"""
Конфигурационный файл для системы детекции объектов
"""

# Настройки устройства для модели
# 'cpu' - использовать CPU (рекомендуется если нет GPU или для стабильности)
# 'cuda' - использовать GPU (если доступен CUDA)
# 'mps' - использовать Apple Silicon GPU (для Mac)
DEVICE = 'cpu'  # По умолчанию CPU

# Настройки модели
MODEL_NAME = 'yolov8n.pt'  # Имя стандартной YOLOv8 модели
# Путь к пользовательским весам (если указан, будет использован вместо MODEL_NAME)
# Пример: '/path/to/your_model.pth' или '/path/to/your_model.pt'
# Важно: .pth должен быть совместим с Ultralytics YOLO. Иначе экспортируйте в .pt/ONNX.
MODEL_PATH = ''

# Настройки Flask сервера
FLASK_HOST = '0.0.0.0'  # 0.0.0.0 позволяет доступ из сети
FLASK_PORT = 5000
FLASK_DEBUG = False

#Создай копию проекта в новой директории (project_pi4/), оптимизированную для Raspberry Pi 4 без ускорителей. Используй облегчённую модель YOLOv8n, уменьшенный размер входного изображения, экспорт в TFLite/ONNX с квантованием. Добавь отдельный config_pi4.py с параметрами для Pi4, оптимизируй ROI‑логику и снизь частоту обработки кадров. Обеспечь минимальные зависимости (ultralytics, onnxruntime, tflite_runtime, opencv-python) и протестируй работу Flask‑сервера на Pi4.



# Настройки видео
VIDEO_SOURCE = 'video_cow.mp4'  # 0 - первая веб-камера, 1 - вторая, или путь к файлу

# Частота захвата кадров с камеры/видео
# Для веб-камеры: обычно 30-60 FPS
# Для видео файла: будет использоваться оригинальная частота файла
CAPTURE_FPS = 60  # Частота захвата кадров с источника

# Частота обработки (детекции объектов)
# Можно установить меньше CAPTURE_FPS для снижения нагрузки на CPU
# Например: CAPTURE_FPS=30, PROCESSING_FPS=10 - захватываем 30 FPS, обрабатываем 10 FPS
PROCESSING_FPS = 30  # Частота обработки кадров детектором (рекомендуется 5-15 для CPU)

# Частота вывода в браузер
# Можно установить меньше PROCESSING_FPS для экономии трафика
OUTPUT_FPS = 60  # Частота отправки кадров в браузер (рекомендуется 10-30)

# Настройки детекции
NO_DATA_TIMEOUT = 2.0  # Время в секундах до показа "Нет данных"
JPEG_QUALITY = 85  # Качество JPEG для трансляции (1-100)
# Чем выше значение, тем лучше качество изображения, но больше размер файла и нагрузка на сеть
# Рекомендуемые значения:
#   70-80  - хороший баланс качества и размера (для медленного интернета)
#   85-95  - высокое качество (по умолчанию 85)
#   95-100 - максимальное качество (большой размер, требует быстрый интернет)

# Настройки ROS (только для object_detection_ros.py)
ROS_TOPIC = '/main_camera/image_raw'  # ROS топик для получения изображений

# Фильтр классов (по именам COCO/вашей модели). Пусто = все классы.
# Примеры: ['cow'] или ['person', 'car']
ALLOWED_CLASSES = ['cow']  # регистронезависимые имена классов

# Настройки трекинга объектов
ENABLE_TRACKING = True  # Включить/выключить трекинг
TRACKER_MAX_AGE = 30  # Максимальное время жизни трека без обновления (в кадрах)
TRACKER_MIN_HITS = 5  # Минимальное количество попаданий для подтверждения трека
TRACKER_IOU_THRESHOLD = 0.4  # Порог IoU для сопоставления детекций с треками
TRACKER_LOST_TIMEOUT = 5.0  # Время в секундах до отправки сигнала о потере объекта

# Настройки компенсации движения камеры
ENABLE_MOTION_COMPENSATION = True  # Включить компенсацию движения камеры
MOTION_COMPENSATION_METHOD = 'optical_flow'  # 'optical_flow' или 'homography'
# optical_flow - быстрее, хорошо для плавного движения
# homography - точнее, лучше для поворотов и масштабирования

# Настройки ROI-логики (для отслеживания потерянных объектов)
ROI_EVENT_TIMEOUT = 10.0  # Время в секундах до генерации события о длительной потере
ROI_EXPANSION = 1.5  # Коэффициент расширения ROI для поиска потерянных объектов
ROI_RECHECK_FRAMES = 10  # Количество кадров до повторной проверки ROI
ROI_NEIGHBOR_OFFSET_RATIO = 0.5  # Смещение соседних областей относительно ROI
ROI_CONFIRMATION_FRAMES = 3  # Минимальное число последовательных кадров для подтверждения объекта

