"""
–°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–µ —Å —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–µ–π —á–µ—Ä–µ–∑ Flask
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç YOLOv8 –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ (–ª—é–¥–µ–π, –º–∞—à–∏–Ω –∏ —Ç.–¥.)
"""

from flask import Flask, Response, render_template, jsonify
import cv2
import threading
import time

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
import config
from models.detector import ObjectDetector
from models.roi_logic import ROILogicManager, ObjectStatus
from utils.network import get_local_ip, print_server_info
from utils.camera import get_camera_source
import logging

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
frame = None
frame_lock = threading.Lock()
detector = None  # –û–±—ä–µ–∫—Ç –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
roi_manager = None  # –ú–µ–Ω–µ–¥–∂–µ—Ä ROI-–ª–æ–≥–∏–∫–∏
last_frame_time = None  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
actual_camera_source = None  # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–∞–º–µ—Ä—ã
current_counts = {}  # –¢–µ–∫—É—â–∏–µ –ø–æ–¥—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
lost_notifications = []  # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
events = []  # –°–æ–±—ã—Ç–∏—è –æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ—Ç–µ—Ä–µ
frame_id = 0  # –°—á–µ—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('tracking.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def draw_tracked_objects(frame, tracked_objects, lost_objects, statistics=None):
    """
    –†–∏—Å—É–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –∏ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –∫–∞–¥—Ä–µ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    
    Args:
        frame: –∫–∞–¥—Ä –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
        tracked_objects: —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –æ—Ç YOLO Track
        lost_objects: —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –æ—Ç ROI-–ª–æ–≥–∏–∫–∏
        statistics: —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º
    """
    h, w = frame.shape[:2]
    
    # –†–∏—Å—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã (–∑–µ–ª–µ–Ω—ã–µ –±–æ–∫—Å—ã —Å ID)
    for obj in tracked_objects:
        x1, y1, x2, y2 = [int(coord) for coord in obj['bbox']]
        track_id = obj.get('track_id')
        class_name = obj['class']
        confidence = obj['confidence']
        
        # –ó–µ–ª–µ–Ω—ã–π –±–æ–∫—Å –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        color = (0, 255, 0)  # –ó–µ–ª–µ–Ω—ã–π
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
        
        # –ú–µ—Ç–∫–∞ —Å ID, –∫–ª–∞—Å—Å–æ–º –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        if track_id is not None:
            label = f"ID:{track_id} {class_name} {confidence:.2f}"
        else:
            label = f"{class_name} {confidence:.2f}"
        (tw, th), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
        cv2.rectangle(frame, (x1, y1 - th - baseline - 5), (x1 + tw + 5, y1), color, -1)
        cv2.putText(frame, label, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    
    # –†–∏—Å—É–µ–º –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (–∫—Ä–∞—Å–Ω—ã–µ –ø—É–Ω–∫—Ç–∏—Ä–Ω—ã–µ –±–æ–∫—Å—ã)
    for obj in lost_objects:
        x1, y1, x2, y2 = [int(coord) for coord in obj['bbox']]
        track_id = obj['track_id']
        class_name = obj['class']
        status = obj.get('status', 'lost')
        time_lost = obj.get('time_lost', 0)
        
        # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç–∞—Ç—É—Å–∞
        if status == 'reappeared':
            color = (255, 165, 0)  # –û—Ä–∞–Ω–∂–µ–≤—ã–π –¥–ª—è –ø–æ—è–≤–∏–≤—à–∏—Ö—Å—è —Å–Ω–æ–≤–∞
        else:
            color = (0, 0, 255)  # –ö—Ä–∞—Å–Ω—ã–π –¥–ª—è –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö
        
        dash_length = 10
        gap_length = 5
        
        # –í–µ—Ä—Ö–Ω—è—è –ª–∏–Ω–∏—è
        x = x1
        while x < x2:
            cv2.line(frame, (x, y1), (min(x + dash_length, x2), y1), color, 2)
            x += dash_length + gap_length
        
        # –ù–∏–∂–Ω—è—è –ª–∏–Ω–∏—è
        x = x1
        while x < x2:
            cv2.line(frame, (x, y2), (min(x + dash_length, x2), y2), color, 2)
            x += dash_length + gap_length
        
        # –õ–µ–≤–∞—è –ª–∏–Ω–∏—è
        y = y1
        while y < y2:
            cv2.line(frame, (x1, y), (x1, min(y + dash_length, y2)), color, 2)
            y += dash_length + gap_length
        
        # –ü—Ä–∞–≤–∞—è –ª–∏–Ω–∏—è
        y = y1
        while y < y2:
            cv2.line(frame, (x2, y), (x2, min(y + dash_length, y2)), color, 2)
            y += dash_length + gap_length
        
        # –ú–µ—Ç–∫–∞ –¥–ª—è –ø–æ—Ç–µ—Ä—è–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        status_text = "REAPPEARED" if status == 'reappeared' else f"LOST ({time_lost:.1f}s)"
        label = f"ID:{track_id} {class_name} ({status_text})"
        (tw, th), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        cv2.rectangle(frame, (x1, y1 - th - baseline - 5), (x1 + tw + 5, y1), color, -1)
        cv2.putText(frame, label, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # –†–∏—Å—É–µ–º ROI –¥–ª—è –ø–æ–∏—Å–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        if obj.get('roi') is not None:
            roi_x1, roi_y1, roi_x2, roi_y2 = obj['roi']
            cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 165, 0), 1)  # –û—Ä–∞–Ω–∂–µ–≤—ã–π –¥–ª—è ROI
    
    # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å–≤–æ–¥–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    if statistics:
        y_offset = 30
        x_offset = 10
        
        # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        summary_lines = []
        for class_name, stats in statistics.items():
            active = stats.get('active', 0)
            total = stats.get('total_detected', 0)
            summary_lines.append(f"{class_name}: {active} –∞–∫—Ç–∏–≤–Ω—ã—Ö / {total} –≤—Å–µ–≥–æ")
        
        if summary_lines:
            max_line_width = max(len(line) for line in summary_lines)
            text_height = len(summary_lines) * 25 + 10
            
            # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
            overlay = frame.copy()
            cv2.rectangle(overlay, (x_offset, y_offset - 20), 
                         (x_offset + max_line_width * 8, y_offset + text_height), 
                         (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
            
            # –¢–µ–∫—Å—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            for i, line in enumerate(summary_lines):
                cv2.putText(frame, line, (x_offset + 5, y_offset + i * 25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    return frame


def video_capture_thread(source):
    """–ü–æ—Ç–æ–∫ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã"""
    global frame, frame_lock, last_frame_time, detector, roi_manager, actual_camera_source, current_counts, lost_notifications, events, frame_id
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –∫–∞–º–µ—Ä—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    actual_source = get_camera_source(source)
    actual_camera_source = actual_source  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
    
    # source –º–æ–∂–µ—Ç –±—ã—Ç—å:
    # - 0 –∏–ª–∏ 1 –¥–ª—è –≤–µ–±-–∫–∞–º–µ—Ä—ã
    # - –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
    # - URL –¥–ª—è IP-–∫–∞–º–µ—Ä—ã
    cap = cv2.VideoCapture(actual_source)
    
    if not cap.isOpened():
        print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ {actual_source}")
        return
    
    print(f"‚úÖ –í–∏–¥–µ–æ–ø–æ—Ç–æ–∫ –æ—Ç–∫—Ä—ã—Ç: {actual_source}")
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º FPS –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ (—Ç–æ–ª—å–∫–æ –¥–ª—è –≤–µ–±-–∫–∞–º–µ—Ä)
    if isinstance(actual_source, int):
        cap.set(cv2.CAP_PROP_FPS, config.CAPTURE_FPS)
        print(f"üìπ –ß–∞—Å—Ç–æ—Ç–∞ –∑–∞—Ö–≤–∞—Ç–∞: {config.CAPTURE_FPS} FPS")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫–∏
    capture_delay = 1.0 / config.CAPTURE_FPS
    processing_delay = 1.0 / config.PROCESSING_FPS
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —á–∞—Å—Ç–æ—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
    frame_count = 0
    last_processing_time = time.time()
    
    print(f"üîç –ß–∞—Å—Ç–æ—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {config.PROCESSING_FPS} FPS")
    print(f"üì§ –ß–∞—Å—Ç–æ—Ç–∞ –≤—ã–≤–æ–¥–∞: {config.OUTPUT_FPS} FPS")
    
    if config.ENABLE_TRACKING:
        print(f"üéØ –¢—Ä–µ–∫–∏–Ω–≥ –≤–∫–ª—é—á–µ–Ω")
    
    while True:
        ret, captured_frame = cap.read()
        if not ret:
            print("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
            break
        
        frame_count += 1
        current_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —ç—Ç–æ—Ç –∫–∞–¥—Ä
        time_since_last_processing = current_time - last_processing_time
        should_process = time_since_last_processing >= processing_delay
        
        if should_process and detector is not None:
            # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã —Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º YOLO Track
            if getattr(config, 'ENABLE_TRACKING', False):
                frame_id += 1
                processed_frame, tracked_objects = detector.detect(
                    captured_frame, 
                    return_detections=True, 
                    use_tracking=True
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º ROI-–ª–æ–≥–∏–∫—É
                if roi_manager is not None:
                    lost_objects, new_events = roi_manager.update(
                        tracked_objects,
                        frame=captured_frame,
                        frame_id=frame_id,
                    )
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º ROI –¥–ª—è –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å—á—ë—Ç)
                    frame_shape = captured_frame.shape
                    for lost_obj in lost_objects:
                        if lost_obj.get('roi') is None:
                            lost_obj_data = roi_manager.lost_objects.get(lost_obj['track_id'])
                            if lost_obj_data:
                                roi = lost_obj_data.get_search_roi(frame_shape, roi_manager.roi_expansion)
                                lost_obj['roi'] = roi
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è
                    if new_events:
                        with frame_lock:
                            events.extend(new_events)
                            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Å–ø–∏—Å–∫–∞ —Å–æ–±—ã—Ç–∏–π
                            if len(events) > 100:
                                events = events[-100:]
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                    with frame_lock:
                        lost_notifications = roi_manager.get_lost_objects()
                
                # –†–∏—Å—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã–µ –∏ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
                if roi_manager is not None:
                    lost_objects = roi_manager.get_lost_objects()
                    statistics = roi_manager.get_statistics()
                    processed_frame = draw_tracked_objects(
                        processed_frame, tracked_objects, lost_objects, statistics
                    )
                    counts = {cls: data.get('active', 0) for cls, data in statistics.items()}
                else:
                    processed_frame = draw_tracked_objects(
                        processed_frame, tracked_objects, [], None
                    )
                    counts = {}
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
                detector.last_counts = counts
            else:
                # –û–±—ã—á–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –±–µ–∑ —Ç—Ä–µ–∫–∏–Ω–≥–∞
                processed_frame = detector.detect(captured_frame)
            
            last_processing_time = current_time
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processed_frame = captured_frame
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä, –≤—Ä–µ–º—è –∏ —Å—á–µ—Ç—á–∏–∫ –æ–±—ä–µ–∫—Ç–æ–≤
        with frame_lock:
            frame = processed_frame
            last_frame_time = time.time()  # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞
            current_counts = detector.last_counts.copy() if detector and detector.last_counts else {}
        
        time.sleep(capture_delay)
    cap.release()


def generate_frames():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞–¥—Ä—ã –¥–ª—è —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–∏"""
    global frame, frame_lock, last_frame_time
    
    frames_sent = 0
    output_delay = 1.0 / config.OUTPUT_FPS
    last_output_time = time.time()
    
    while True:
        with frame_lock:
            current_time = time.time()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–æ –ª–∏ –±–æ–ª–µ–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞
            if frame is not None and last_frame_time is not None:
                time_since_last_frame = current_time - last_frame_time
                if time_since_last_frame <= config.NO_DATA_TIMEOUT:
                    # –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º —á–∞—Å—Ç–æ—Ç—É –≤—ã–≤–æ–¥–∞
                    time_since_last_output = current_time - last_output_time
                    if time_since_last_output >= output_delay:
                        # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞–¥—Ä –≤ JPEG
                        try:
                            ret, buffer = cv2.imencode('.jpg', frame, 
                                                       [cv2.IMWRITE_JPEG_QUALITY, config.JPEG_QUALITY])
                            if ret:
                                frame_bytes = buffer.tobytes()
                                frames_sent += 1
                                last_output_time = current_time
                                if frames_sent % 100 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 100 –∫–∞–¥—Ä–æ–≤
                                    print(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {frames_sent}")
                                
                                yield (b'--frame\r\n'
                                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

                        except Exception as e:
                            print(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–¥—Ä–∞: {e}")
            else:
                # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∫–∞–¥—Ä–æ–≤
                if frames_sent == 0:
                    if frame is None:
                        print("‚ö†Ô∏è  –ö–∞–¥—Ä –µ—â–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω...")
                    elif last_frame_time is None:
                        print("‚ö†Ô∏è  –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ...")
                    else:
                        time_since_last = current_time - last_frame_time
                        if time_since_last > config.NO_DATA_TIMEOUT:
                            print(f"‚ö†Ô∏è  –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: {time_since_last:.2f} —Å–µ–∫")
        
        delay = output_delay - (time.time() - current_time)
        if delay > 0:
            time.sleep(delay) 


@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–∏–¥–µ–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    global actual_camera_source, current_counts
    import time as time_module

    with frame_lock:
        counts_snapshot = current_counts.copy() if current_counts else {}
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
    if actual_camera_source is not None:
        if isinstance(actual_camera_source, int):
            source_info = f"–í–µ–±-–∫–∞–º–µ—Ä–∞ #{actual_camera_source}"
        else:
            source_info = str(actual_camera_source)
    else:
        # –ï—Å–ª–∏ –∫–∞–º–µ—Ä–∞ –µ—â–µ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        if isinstance(config.VIDEO_SOURCE, int):
            source_info = f"–í–µ–±-–∫–∞–º–µ—Ä–∞ #{config.VIDEO_SOURCE}"
        else:
            source_info = str(config.VIDEO_SOURCE)
    
    # –î–æ–±–∞–≤–ª—è–µ–º timestamp –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    timestamp = int(time_module.time() * 1000)
    
    return render_template(
        'index.html',
        source_info=source_info,
        timestamp=timestamp,
        counts=counts_snapshot,
        model_name=config.MODEL_NAME
    )


@app.route('/video_feed')
def video_feed():
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞"""
    return Response(
        generate_frames(),
        mimetype='multipart/x-mixed-replace; boundary=frame',
        headers={
            'Cache-Control': 'no-cache, no-store, must-revalidate',
            'Pragma': 'no-cache',
            'Expires': '0'
        }
    )

@app.route('/counts')
def get_counts():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –ø–æ–¥—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã"""
    with frame_lock:
        counts_snapshot = current_counts.copy() if current_counts else {}
    return jsonify({
        'counts': counts_snapshot,
        'timestamp': time.time()
    })


@app.route('/lost_notifications')
def get_lost_notifications():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞—Ö"""
    global lost_notifications
    with frame_lock:
        notifications_snapshot = lost_notifications.copy() if lost_notifications else []
    return jsonify(notifications_snapshot)

@app.route('/events')
def get_events():
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ—Ç–µ—Ä–µ –æ–±—ä–µ–∫—Ç–æ–≤"""
    global events
    with frame_lock:
        events_snapshot = events.copy() if events else []
    return jsonify(events_snapshot)


if __name__ == '__main__':
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ config
    # detector —É–∂–µ –æ–±—ä—è–≤–ª–µ–Ω–∞ –∫–∞–∫ –≥–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –º–æ–¥—É–ª—è
    print(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞...")
    print(f"–ú–æ–¥–µ–ª—å: {config.MODEL_NAME}")
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {config.DEVICE}")
    detector = ObjectDetector(
        model_name=config.MODEL_NAME,
        device=config.DEVICE,
        model_path=getattr(config, 'MODEL_PATH', '') or '',
        allowed_classes=getattr(config, 'ALLOWED_CLASSES', None)
    )
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ROI-–º–µ–Ω–µ–¥–∂–µ—Ä –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ç—Ä–µ–∫–∏–Ω–≥
    if getattr(config, 'ENABLE_TRACKING', False):
        lost_timeout = getattr(config, 'TRACKER_LOST_TIMEOUT', 5.0)
        event_timeout = getattr(config, 'ROI_EVENT_TIMEOUT', 10.0)
        roi_expansion = getattr(config, 'ROI_EXPANSION', 1.5)
        iou_threshold = getattr(config, 'TRACKER_IOU_THRESHOLD', 0.3)
        recheck_frames = getattr(config, 'ROI_RECHECK_FRAMES', 10)
        neighbor_offset_ratio = getattr(config, 'ROI_NEIGHBOR_OFFSET_RATIO', 0.5)
        confirmation_frames = getattr(config, 'ROI_CONFIRMATION_FRAMES', 3)
        
        roi_manager = ROILogicManager(
            lost_timeout=lost_timeout,
            event_timeout=event_timeout,
            roi_expansion=roi_expansion,
            iou_threshold=iou_threshold,
            recheck_frames=recheck_frames,
            neighbor_offset_ratio=neighbor_offset_ratio,
            confirmation_frames=confirmation_frames
        )
        logger.info("‚úÖ YOLO Track —Å ByteTrack –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"   Lost timeout: {lost_timeout} —Å–µ–∫")
        logger.info(f"   Event timeout: {event_timeout} —Å–µ–∫")
        logger.info(f"   ROI expansion: {roi_expansion}")
        logger.info(f"   IoU threshold: {iou_threshold}")
        logger.info(f"   ROI recheck frames: {recheck_frames}")
        logger.info(f"   ROI neighbor offset ratio: {neighbor_offset_ratio}")
        logger.info(f"   Confirmation frames: {confirmation_frames}")
    else:
        roi_manager = None
        logger.info("‚ö†Ô∏è  –¢—Ä–µ–∫–∏–Ω–≥ –æ—Ç–∫–ª—é—á–µ–Ω")
    
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞, —á—Ç–æ–±—ã –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ç–æ—á–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª—Å—è
    time.sleep(0.5)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ
    video_thread = threading.Thread(
        target=video_capture_thread, 
        args=(config.VIDEO_SOURCE,), 
        daemon=True
    )
    video_thread.start()
    
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —Å–µ—Ä–≤–µ—Ä–∞, —á—Ç–æ–±—ã –ø–æ—Ç–æ–∫ —É—Å–ø–µ–ª –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É
    time.sleep(1.0)
    
    # –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π IP-–∞–¥—Ä–µ—Å –∏ –≤—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    local_ip = get_local_ip()
    print_server_info(local_ip, config.FLASK_PORT)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º Flask —Å–µ—Ä–≤–µ—Ä
    app.run(
        host=config.FLASK_HOST, 
        port=config.FLASK_PORT, 
        debug=config.FLASK_DEBUG, 
        threaded=True
    )
